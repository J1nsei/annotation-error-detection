# Annotation error searching tool

## Описание
Инструмент, предназначенный для упрощения и автоматизации процесса анализа аннотаций данных в контексте обнаружения объектов. Он предоставляет мощные возможности для обнаружения и отображения ошибок в аннотациях к данным, таких как неправильно размещенные метки классов, неправильно определенные ограничивающие рамки или даже отсутствующие аннотации. Кроме того, есть полезная визуализация ошибок с помощью FiftyOne, а также анализ их вклада в метрику mAP.
### Типы ошибок:
- **Classification error (CLS)**: неправильная метка класса (т.е. локализована правильно, но неправильно классифицирована).
- **Localization error (LOC)**: неправильно локализован, правильно классифицирован.
- **Classification and Localization error (CLS & LOC)**: неправильная классификация и локализация одновременно.
- **Duplicate detection error (DUP)**: цель обнаружена правильно, но существует более точное обнаружение (показатель достоверности выше).
- **Background error (BKG)**: фон обнаружен как передний план.
- **Missed target error (MISS)**: необнаруженные цели, которые не были помечены как ошибки классификации или локализации.


## Установка
1. Установите Python >= 3.10.
2. Установите [PyTorch](https://pytorch.org/get-started/locally/).
3. Установите зависимости:
```python -m pip install -r requirements.txt```

## Использование
- Запуск в режиме поиска ошибок:
    - Linux:
        ``` python3 main.py --data='./dataset' --model='./models/default/demo.pt' --train=False --impact=True ```

    - Windows:
        ``` python main.py --data=".\\dataset" --model=".\\models\\default\\demo.pt" --train=False --impact=True ```
    - Датафрейм с ошибками будет сохранен в папке errors_found.
- Запуск в режиме обучения:
    - Для первого запуска обучения необходимо создать датасет для YOLO модели (--create_dataset), а также выбрать подвыборку для теста (--labels):
        ``` python3 main.py --data='./dataset' --model='./models/default/demo.pt' --train=Train --create_dataset=True --labels="labels_1.json"```
    - После создания датасета, данные разделятся на 5 комбинаций: data_N.yaml. Каждой комбинации соответствует своя тестовая выбора labels_N.json, которая не учавствует в обучении и валидации модели. Также обучатся 5 моделей YOLO, лучшие веса для каждой подвыборки будут находится в соответствующей папке trained_yolo/split/weights/best.pt.
    - Последующие запуски обучения:
        ``` python3 main.py --data='./dataset' --model='./models/default/demo.pt' --train=Train --labels="labels_2.json"```
- Описание параметров:
    - **data** = './dataset' (путь к директории с датасетом).
    - **model** = './models/my_model.pt' (путь к модели)
    - **impact** = True (включение анализа влияния ошибок на метрику mAP)
    - **labels** = 'labels_N.json' (выбор подмножества разметки данных)
    - **preds** = 'preds_N.pkl' (выбор подмножества предсказаний, предсказания в формате pd.DataFrame(columns=['pred_id', 'image_id', 'label_id', 'xmin', 'ymin', 'w', 'h', 'score']))
    - **save_preds** = True (сохранение предсказаний)
## Формат и хранение данных
- Данные должны быть размечены в **COCO** формате.
- Формат хранения:
    ```bash
    ├── dataset
    │   ├── labels.json  <--------- файл аннотации
    │   └── images       <--------- папка с изображениями
    │       ├── img1.jpg
    │       ├── ...
    │       └── imgN.jpg
    ├── models
    ├── utils
    ├── main.py
    └── README.md
    ```
## Использование собственной модели
Чтобы использовать свою собственную обученную модель YOLOv8, поместите файл с весами в папку *models* и укажите путь к ним при запуске (``--model='./models/my_model.pt"` ).

